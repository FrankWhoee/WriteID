Are Self-Driving Cars Ready for the Road? An Ethical Analysis of Autonomous Vehicles


Introduction
        Driving is becoming increasingly trivial, especially with the recent development of autonomous vehicles. Introducing self-driving cars could provide safety and efficiency by removing the factor of human error (Fleetwood 532). Yet in 2019, there is debate around the extent that autonomous vehicles should be allowed on the road. In this stage of development, autonomous vehicle testing has already demonstrated a decrease in accidents (Favarò et al. 8). Furthermore, the general populations of North America and Europe are optimistic about the development of AVs (Schoettle and Sivak 26). Despite this, many ethical and moral dilemmas remain unresolved, meaning more theoretical and practical testing must be completed before the mass market of autonomous cars.
Public Safety
        Autonomous vehicles have already been proven to be less accident-prone than other vehicles. In an in-depth examination of accident reports involving autonomous vehicles in California—among a sample of 28 individual accidents—autonomous vehicles had a lower accident rate compared to non-AVs (Favarò et al. 8). Of these accidents, 62% were rear-enders, compared to 30% of conventional vehicles. At first, this appears to be a 200% increase in collisions, but Favarò and colleagues concluded a reduction of other collisions was the cause for this skew (8). An article by Jane Fleetwood, Ph.D. and representative of the Department of Community Health and Prevention, argues that autonomous cars could reduce up to 90% of vehicular accidents, and save 29 000 lives in the United States alone (532).  Human error causes up to 94% of all vehicular accidents (Fleetwood 532; Favarò et al. 1), meaning removing the human factor could drastically reduce collision rates. One issue with this simple assertion, described by Leon and Martens in their 2015 paper (qtd. from Nyholm and Smids 1278), is that manual and autonomous vehicles will coexist on public roads, meaning reductions in human-caused accidents will not be as drastic as estimated.
        There are many ethical dilemmas surrounding the mass production of AVs. Tobias Holstein, from Mälardalen University, and his colleagues from the Chalmers University of Technology, pose several questions concerning the development of autonomous vehicles. Should manufacturers be allowed to sacrifice performance for a lower price (4)? Should the AV be fully disconnected, providing security from cyber attacks, or should they stay online, for quick updates and better communication between vehicles (5)? These are some crucial questions that still have no conclusive answers.
Liability and Legality
        Responsibility is another factor to consider when developing autonomous vehicles. For most drivers, the “sudden emergency doctrine” and the “unavoidable accident doctrine” both provide protection in an accident situation where an injury is unavoidable (Fleetwood 534), but should these principles be applied to autonomous vehicles? 
Patrick Lin, director of the Ethics and Emerging Sciences group at the California Polytechnic State University, explains in his journal report on Tesla’s lawsuit regarding its automatic emergency braking (AEB), how Tesla prefers to allow the driver take responsibility. Tesla vehicles did not activate the AEB system when they detected a driver in control of the vehicle, even if the AEB could prevent harm. Lin describes Tesla’s reasoning as being one of liability: if the AEB system activates and the vehicle skids into a pedestrian, Tesla becomes responsible for this incident. This extends a question posed by Holstein and colleagues: should businesses sacrifice moral imperatives in pursuit of company interests (4)?
Legal infrastructure is being developed to answer these questions. The German Ethics Commission provided the first legal document on the regulation of AVs. In their report, they state that the autonomous cars must be governed by the same principles of other products, in terms of who is liable for damage (Germany, Automated and Connected Driving 12). In agreeance with Tesla, rule 16 from the report states that systems must be designed to clearly differentiate between a person and a machine, and when a person is in control, the responsibility falls upon that entity (Germany, Automated and Connected Driving 13). A split-responsibility model seems to be the most effective at maintaining the autonomy of a person while also ensuring safety and responsibility on behalf of the automakers.
The Trolley Problem
        At the centre of most ethical discussions around AVs is the trolley problem. The trolley problem is a philosophical dilemma in which a person, acting as a trolley car operator, chooses to either kill five people through inaction or switch the tracks to end the life of one. It has many different contexts and is generally agreed to have relevance towards autonomous driving (Nyholm and Smids 1276), but no conclusive decision has been made on exactly how cars should react. In a mass scale study titled “The Moral Machine,” Edmond Awad and his colleagues from the Massachusetts Institute of Technology, collected 39.61 million ethical decisions on similar dilemmas, from 233 countries worldwide (59). They believe that citizens should be the final decision makers when legislating ethical decisions because, no matter how many ethicists agree, if citizens disagree the product will not be adopted (Awad et al. 59). However, achieving a general consensus is difficult, as people have differing opinions based on culture and region.
        In their study, Awad and colleagues found a massive divide between respondents, based on the country they lived in (62). These countries were classified as either Eastern, Western, or Southern in terms of ideology. In these three classifications, huge discrepancies were found between preferences in actions. For example, Eastern countries were seen to spare the lawful much more than Western countries, yet have a very negative favouring towards the young (Awad et al. 62). On the other hand, Southern countries had a much higher preference for the young, while having a very low preference for inaction (Awad et al. 62). Though global consensus is difficult to ascertain, general preferences can be made evident.
        Jean-François Bonnefon and colleagues find, in their study on the ethics of autonomous vehicles, that 76% of the respondents prefer autonomous vehicles to sacrifice the passengers if ten lives would be lost otherwise (1574). However, when further surveyed, a minority amount of respondents replied that they would buy a vehicle where such a trade-off was regulated, with an almost 200% increase in acceptance if the vehicle was unregulated (Bonnefon et al. 1575). This demonstrates the dichotomy between people’s utilitarian ideals and their actual preferences.
        Sven Nyholm, a faculty member of the Philosophy and Ethics of Technology at the Eindhoven University of Technology, and his colleague, Jilles Smid, argue that the discussion of autonomous vehicles should involve all stakeholders (1281). Holstein and colleagues echo this sentiment (7). Nyholm and Smids use the multiple stakeholders as a disanalogy against the trolley problem and its application to autonomous vehicles, describing how a moral dilemma could involve more than just the people in the collision, but the stakeholders as well (1281).
        Nyholm and Smids present two other disanalogies between the trolley problem and reality: the uncertainty and variables in realistic situations, and the impact of moral and legal responsibilities that arise because of the trolley problem (1281-1285). Despite a majority public agreement on the trolley problem’s relevance to autonomous driving—from economists, ethicists, psychologists, and philosophers—there still must be an overreliance on the trolley problem as the only analogy when making accident-algorithms (Nyholm and Smids 1276; Goodall 496).  
        Another contention regarding the trolley problem is its triviality regarding reality. The proposition of the trolley problem does not apply to the mundane tasks in everyday life, such as decision making at a crosswalk (Himmelreich). It also disregards superior courses of action, such as applying the brakes (Goodall 496). Either way, it is important to recognize the basic structure of such dilemmas, despite the disanalogies (Fleetwood 534), but a focus on other practical dilemmas may be more useful in the development of AVs (Holstein et al. 7). 
Conclusion
        Many considerations are packaged into the development of autonomous vehicles, yet the final decision on how they should be dealt with is still not clear. While democratic governments value a majority rules system for delegation, public consensus is much more important in terms of autonomous vehicles, as they have the potential to affect people around the globe. Many citizens in both the U.S. and the U.K. are optimistic about the benefits of autonomous vehicles (Schoettle and Sivak 26). Regarding autonomous vehicles, deployment on public roads, especially in a mass format, is not a question of if, but when. Due to discrepancies in these ethical discussions, this question can’t quite be answered. Autonomous cars still require more training, ethical guidelines, and practical experience before mass deployment on public roads.